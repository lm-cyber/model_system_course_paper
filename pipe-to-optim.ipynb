{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/void/test/venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:165: UserWarning: The following named arguments are not valid for `SegformerImageProcessor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import json\n",
    "from huggingface_hub import hf_hub_download\n",
    "import requests, zipfile, io\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    SegformerForSemanticSegmentation,\n",
    ")\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training  validation\n"
     ]
    }
   ],
   "source": [
    "!ls ADEChallengeData2016/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat ADEChallengeData2016/objectInfo150.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, image_processor, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory of the dataset containing the images + annotations.\n",
    "            image_processor (SegFormerImageProcessor): image processor to prepare images + segmentation maps.\n",
    "            train (bool): Whether to load \"training\" or \"validation\" images + annotations.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.image_processor = image_processor\n",
    "        self.train = train\n",
    "\n",
    "        sub_path = \"training\" if self.train else \"validation\"\n",
    "        self.img_dir = os.path.join(self.root_dir, \"images\", sub_path)\n",
    "        print(self.img_dir)\n",
    "        self.ann_dir = os.path.join(self.root_dir, \"annotations\", sub_path)\n",
    "\n",
    "        # read images\n",
    "        image_file_names = []\n",
    "        for root, dirs, files in os.walk(self.img_dir):\n",
    "          image_file_names.extend(files)\n",
    "        self.images = sorted(image_file_names)\n",
    "\n",
    "        # read annotations\n",
    "        annotation_file_names = []\n",
    "        for root, dirs, files in os.walk(self.ann_dir):\n",
    "          annotation_file_names.extend(files)\n",
    "        self.annotations = sorted(annotation_file_names)\n",
    "\n",
    "        assert len(self.images) == len(self.annotations), \"There must be as many images as there are segmentation maps\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def get_name_file(self,idx):\n",
    "        return os.path.join(self.img_dir, self.images[idx]),os.path.join(self.ann_dir, self.annotations[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(os.path.join(self.img_dir, self.images[idx]))\n",
    "        segmentation_map = Image.open(os.path.join(self.ann_dir, self.annotations[idx]))\n",
    "\n",
    "        # randomly crop + pad both image and segmentation map to same size\n",
    "        encoded_inputs = self.image_processor(image, segmentation_map, return_tensors=\"pt\")\n",
    "\n",
    "        for k,v in encoded_inputs.items():\n",
    "          encoded_inputs[k].squeeze_() # remove batch dimension\n",
    "\n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 512)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segmentation_map = Image.open('ADEChallengeData2016/annotations/training/ADE_train_00000001.png')\n",
    "# segmentation_map.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 512)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image.fromarray(np.array(segmentation_map)-1).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   4,   5,   6,  13,  18,  32,  33,  43,  44,  88,  97,\n",
       "       105, 126, 139, 150], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(np.array(segmentation_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   3,   4,   5,  12,  17,  31,  32,  42,  43,  87,  96, 104,\n",
       "       125, 138, 149, 255], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.unique(np.array(segmentation_map)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ADEChallengeData2016/images/training/ADE_train_00000001.jpg',\n",
       " 'ADEChallengeData2016/annotations/training/ADE_train_00000001.png')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset.get_name_file(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADEChallengeData2016/images/training\n",
      "ADEChallengeData2016/images/validation\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor\n",
    "\n",
    "root_dir = 'ADEChallengeData2016'\n",
    "image_processor = SegformerImageProcessor(reduce_labels=True)\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(root_dir=root_dir, image_processor=image_processor)\n",
    "valid_dataset = SemanticSegmentationDataset(root_dir=root_dir, image_processor=image_processor, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrapted = []\n",
    "# for i in tqdm(range(len(train_dataset))):\n",
    "#     try:\n",
    "#         train_dataset[i]\n",
    "#     except:\n",
    "#         corrapted.append(train_dataset.get_name_file(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm_rf_str = []\n",
    "# for i in corrapted:\n",
    "#     rm_rf_str.extend(i)\n",
    "# rm_rf_str = ' '.join(rm_rf_str)\n",
    "# rm_rf_str\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size=8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,num_workers=14, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,num_workers=14,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as tp\n",
    "import torch\n",
    "\n",
    "from copy import deepcopy\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from transformers.models.segformer.modeling_segformer import SegformerLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "# from evaluate import load_metric\n",
    "from torch import nn\n",
    "import evaluate\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "def evaluate_model(model, valid_dataloader, id2label):\n",
    "    metric = evaluate.load(\"mean_iou\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in valid_dataloader:\n",
    "            pixel_values = batch[\"pixel_values\"].cuda()\n",
    "            labels = batch[\"labels\"].cuda()\n",
    "            logits = model(pixel_values=pixel_values, labels=labels)\n",
    "            upsampled_logits = nn.functional.interpolate(\n",
    "                logits.logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "            )\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            predictions.append(predicted.detach().cpu().numpy())\n",
    "            references.append(labels.detach().cpu().numpy())\n",
    "\n",
    "        # note that the metric expects predictions + labels as numpy arrays\n",
    "\n",
    "    metrics = metric._compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        num_labels=len(id2label),\n",
    "        ignore_index=255,\n",
    "        reduce_labels=False,  # we've already reduced the labels before)\n",
    "    )\n",
    "\n",
    "    print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "    print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.36103305469415725\n",
      "Mean accuracy: 0.4731817117838845\n"
     ]
    }
   ],
   "source": [
    "m = evaluate_model(model, valid_dataloader, model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_network(model):\n",
    "    future_list_names = {}\n",
    "\n",
    "    for name, curr_module in model.named_modules():\n",
    "        if isinstance(curr_module, nn.ModuleList):\n",
    "            list_of_modules = [\n",
    "                sub_module\n",
    "                for sub_module in curr_module.children()\n",
    "                if isinstance(sub_module, SegformerLayer)\n",
    "            ]\n",
    "            if len(list_of_modules) > 1:\n",
    "                future_list_names[name] = nn.ModuleList([list_of_modules[-1]])\n",
    "\n",
    "    setattr(model.segformer.encoder, 'block', nn.ModuleList(list(future_list_names.values())))\n",
    "\n",
    "    return model\n",
    "\n",
    "def n_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = create_small_network(deepcopy(teacher_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6062923168193761"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params(teacher_model) / n_params(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_epochs: int\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    n_workers: int\n",
    "    device: torch.device\n",
    "\n",
    "    loss_weight: float\n",
    "    last_layer_loss_weight: float\n",
    "    intermediate_attn_layers_weights: tp.Tuple[float, float, float, float]\n",
    "    intermediate_feat_layers_weights: tp.Tuple[float, float, float, float]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'distil'\n",
    "tb_writer = SummaryWriter(save_dir)\n",
    "def train(\n",
    "    teacher_model,\n",
    "    student_model,\n",
    "    train_params: TrainParams,\n",
    "    student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir='distil',\n",
    "):\n",
    "    metric = evaluate.load('mean_iou')\n",
    "    teacher_model.to(train_params.device)\n",
    "    student_model.to(train_params.device)\n",
    "\n",
    "    teacher_model.eval()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=train_params.lr)\n",
    "    step = 0\n",
    "    for epoch in range(train_params.n_epochs):\n",
    "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for idx, batch in pbar:\n",
    "            student_model.train()\n",
    "            # get the inputs;\n",
    "            pixel_values = batch['pixel_values'].to(train_params.device)\n",
    "            labels = batch['labels'].to(train_params.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            student_outputs = student_model(\n",
    "                pixel_values=pixel_values, \n",
    "                labels=labels, \n",
    "                output_attentions=True,\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "            loss, student_logits = student_outputs.loss, student_outputs.logits\n",
    "\n",
    "            # Чего это мы no_grad() при тренировке поставили?!\n",
    "            with torch.no_grad():\n",
    "                teacher_output = teacher_model(\n",
    "                    pixel_values=pixel_values, \n",
    "                    labels=labels, \n",
    "                    output_attentions=True,\n",
    "                    output_hidden_states=True,\n",
    "                )\n",
    "\n",
    "\n",
    "            last_layer_loss = calc_last_layer_loss(\n",
    "                student_logits,\n",
    "                teacher_output.logits,\n",
    "                train_params.last_layer_loss_weight,\n",
    "            )\n",
    "\n",
    "            student_attentions, teacher_attentions = student_outputs.attentions, teacher_output.attentions\n",
    "            student_hidden_states, teacher_hidden_states = student_outputs.hidden_states, teacher_output.hidden_states\n",
    "\n",
    "            intermediate_layer_att_loss = calc_intermediate_layers_attn_loss(\n",
    "                student_attentions,\n",
    "                teacher_attentions,\n",
    "                train_params.intermediate_attn_layers_weights,\n",
    "                student_teacher_attention_mapping,\n",
    "            )\n",
    "            \n",
    "            intermediate_layer_feat_loss = calc_intermediate_layers_feat_loss(\n",
    "                student_hidden_states,\n",
    "                teacher_hidden_states,\n",
    "                train_params.intermediate_feat_layers_weights,\n",
    "            )\n",
    "\n",
    "            total_loss = loss* train_params.loss_weight + last_layer_loss\n",
    "            if intermediate_layer_att_loss is not None:\n",
    "                total_loss += intermediate_layer_att_loss\n",
    "            \n",
    "            if intermediate_layer_feat_loss is not None:\n",
    "                total_loss += intermediate_layer_feat_loss\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f'total loss: {total_loss.item():.3f}')\n",
    "\n",
    "            for loss_value, loss_name in (\n",
    "                (loss, 'loss'),\n",
    "                (total_loss, 'total_loss'),\n",
    "                (last_layer_loss, 'last_layer_loss'),\n",
    "                (intermediate_layer_att_loss, 'intermediate_layer_att_loss'),\n",
    "                (intermediate_layer_feat_loss, 'intermediate_layer_feat_loss'),\n",
    "            ):\n",
    "                if loss_value is None: # для выключенной дистилляции атеншенов\n",
    "                    continue\n",
    "                tb_writer.add_scalar(\n",
    "                    tag=loss_name,\n",
    "                    scalar_value=loss_value.item(),\n",
    "                    global_step=step,\n",
    "                )\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'model': student_model,\n",
    "                'state_dict': student_model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "            },\n",
    "            f'{save_dir}/ckpt_{epoch}.pth',\n",
    "        )\n",
    "\n",
    "        eval_metrics = evaluate_model(student_model, valid_dataloader, student_model.config.id2label)\n",
    "\n",
    "        for metric_key, metric_value in eval_metrics.items():\n",
    "            if not isinstance(metric_value, float):\n",
    "                continue\n",
    "            tb_writer.add_scalar(\n",
    "                tag=f'eval_{metric_key}',\n",
    "                scalar_value=metric_value,\n",
    "                global_step=epoch,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "kl_loss = nn.KLDivLoss()\n",
    "\n",
    "def calc_last_layer_loss(student_logits, teacher_logits, weight):\n",
    "    return mse_loss(student_logits, teacher_logits) * weight\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_teacher_attention_mapping = {0: 1, 1: 3, 2: 5, 3: 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_intermediate_layers_loss(student_attentions, teacher_attentions, weights, student_teacher_attention_mapping):\n",
    "    intermediate_kl_loss = 0\n",
    "    for i, (stud_attn_idx, teach_attn_idx) in enumerate(student_teacher_attention_mapping.items()):\n",
    "        intermediate_kl_loss += weights[i] * kl_loss(\n",
    "            input=torch.log(student_attentions[stud_attn_idx]),\n",
    "            target=teacher_attentions[teach_attn_idx],\n",
    "        )\n",
    "    return intermediate_kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_intermediate_layers_feat_loss(student_feats, teacher_feats, weights):\n",
    "    intermediate_mse_loss = 0.\n",
    "    for i in range(len(student_feats)):\n",
    "        intermediate_mse_loss += weights[i] * mse_loss(\n",
    "            input=student_feats[i],\n",
    "            target=teacher_feats[i],\n",
    "        )\n",
    "    return intermediate_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = TrainParams(\n",
    "    n_epochs=3,\n",
    "    lr=6e-5,\n",
    "    batch_size=8,\n",
    "    n_workers=8,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    loss_weight=1,\n",
    "    last_layer_loss_weight=0.,\n",
    "    intermediate_attn_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
    "    intermediate_feat_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 2.771: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [09:55<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.3225399390426699\n",
      "Mean accuracy: 0.4294977320749136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 2.963: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [09:54<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.33518421276488785\n",
      "Mean accuracy: 0.4314515815548881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 2.896: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [09:55<00:00,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.33927428285885625\n",
      "Mean accuracy: 0.43623544028562903\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=deepcopy(student_model),\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat ADEChallengeData2016/objectInfo150.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   3,   4,   5,  12,  17,  31,  32,  42,  43,  87,  96, 104,\n",
       "       125, 138, 149, 255])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np \n",
    "# np.unique(train_dataset[0]['labels'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.get_name_file(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_0.pth\n",
      "ckpt_1.pth\n",
      "ckpt_2.pth\n",
      "events.out.tfevents.1734576225.archlinux.8485.0\n",
      "events.out.tfevents.1734576943.archlinux.10931.0\n",
      "events.out.tfevents.1734577628.archlinux.12550.0\n",
      "events.out.tfevents.1734578383.archlinux.14706.0\n"
     ]
    }
   ],
   "source": [
    "!ls distil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14706/2204379903.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  distilled_model = torch.load('distil/ckpt_2.pth')[\"model\"]\n"
     ]
    }
   ],
   "source": [
    "distilled_model = torch.load('distil/ckpt_2.pth')[\"model\"]\n",
    "teacher_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "teacher_model.to(device)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.33627428285885625\n",
      "Mean accuracy: 0.43623544028562903\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(distilled_model, valid_dataloader, distilled_model.config.id2label)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.36103305469415725\n",
      "Mean accuracy: 0.4731817117838845\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(teacher_model, valid_dataloader, teacher_model.config.id2label)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model complexity: 7384.410112 MMAC, 3.752694 M params\n"
     ]
    }
   ],
   "source": [
    "import torch_pruning as tp\n",
    "input_example = torch.rand(1,3,512,512, device=\"cuda\")\n",
    "ops, params = tp.utils.count_ops_and_params(teacher_model, input_example)\n",
    "print(f\"Baseline model complexity: {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity: 6465.00096 MMAC, 2.336246 M params\n"
     ]
    }
   ],
   "source": [
    "ops, params = tp.utils.count_ops_and_params(distilled_model, input_example)\n",
    "print(f\"Distilled model complexity: {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_pruning as tp\n",
    "taylor_criteria = tp.importance.GroupTaylorImportance()\n",
    "input_example = torch.rand(1,3,512,512, device=\"cuda\")\n",
    "ignored_layers = []\n",
    "for name, module in distilled_model.named_modules():\n",
    "    if name == \"decode_head.classifier\":\n",
    "        ignored_layers.append(module)\n",
    "\n",
    "pruner = tp.pruner.MetaPruner(\n",
    "        distilled_model,\n",
    "        example_inputs=input_example,\n",
    "        importance=taylor_criteria,\n",
    "        pruning_ratio=0.75,\n",
    "        global_pruning=False,\n",
    "        ignored_layers=ignored_layers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████████████████████████████████| 2526/2526 [06:00<00:00,  7.01it/s]"
     ]
    }
   ],
   "source": [
    "distilled_model.train()\n",
    "for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "    # get the inputs;\n",
    "    pixel_values = batch[\"pixel_values\"].to(\"cuda\")\n",
    "    labels = batch[\"labels\"].to(\"cuda\")\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = distilled_model(pixel_values=pixel_values, labels=labels)\n",
    "    loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(pruner.step(interactive=True)):\n",
    "    g.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.segformer.modeling_segformer import SegformerLayer, SegformerEfficientSelfAttention\n",
    "\n",
    "for module in distilled_model.modules():\n",
    "    if isinstance(module, SegformerEfficientSelfAttention):\n",
    "        module.attention_head_size = module.attention_head_size // 4\n",
    "        module.all_head_size = module.all_head_size // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distilled model complexity (After taylor pruning): 550.512 MMAC, 0.160238 M params\n"
     ]
    }
   ],
   "source": [
    "ops, params = tp.utils.count_ops_and_params(distilled_model, input_example)\n",
    "print(f\"Distilled model complexity (After taylor pruning): {ops/1e6} MMAC, {params/1e6} M params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'prune'\n",
    "tb_writer = SummaryWriter(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "@dataclass\n",
    "class TrainParams:\n",
    "    n_epochs: int\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    n_workers: int\n",
    "    device: torch.device\n",
    "\n",
    "    temperature: float\n",
    "    loss_weight: float\n",
    "    last_layer_loss_weight: float\n",
    "    intermediate_layers_weights: typing.Tuple[float, float, float, float]\n",
    "train_params = TrainParams(\n",
    "    n_epochs=10,\n",
    "    lr=1e-4,\n",
    "    batch_size=16,\n",
    "    n_workers=8,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    temperature=10,\n",
    "    loss_weight=0.5,\n",
    "    last_layer_loss_weight=0.5,\n",
    "    intermediate_layers_weights=(0.5, 0.5, 0.5, 0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_last_layer_loss(student_logits, teacher_logits, temperature, weight):\n",
    "    return kl_loss(\n",
    "        input=F.log_softmax(student_logits / temperature, dim=-1),\n",
    "        target=F.softmax(teacher_logits / temperature, dim=-1),\n",
    "    ) * temperature ** 2\n",
    "    return loss\n",
    "\n",
    "def calc_intermediate_layers_loss(student_attentions, teacher_attentions, weights, student_teacher_attention_mapping):\n",
    "    intermediate_kl_loss = 0\n",
    "    for i, (stud_attn_idx, teach_attn_idx) in enumerate(student_teacher_attention_mapping.items()):\n",
    "        intermediate_kl_loss += weights[i] * kl_loss(\n",
    "            input=torch.log(student_attentions[stud_attn_idx]),\n",
    "            target=teacher_attentions[teach_attn_idx],\n",
    "        )\n",
    "    return intermediate_kl_loss\n",
    "\n",
    "def train(\n",
    "    teacher_model,\n",
    "    student_model,\n",
    "    train_params: TrainParams,\n",
    "    student_teacher_attention_mapping,\n",
    "    tb_writer,\n",
    "    save_dir,\n",
    "):\n",
    "    metric = evaluate.load('mean_iou')\n",
    "    teacher_model.to(train_params.device)\n",
    "    student_model.to(train_params.device)\n",
    "\n",
    "    teacher_model.eval()\n",
    "\n",
    " \n",
    "\n",
    "    optimizer = torch.optim.AdamW(student_model.parameters(), lr=train_params.lr)\n",
    "    step = 0\n",
    "    for epoch in range(train_params.n_epochs):\n",
    "        pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "        for idx, batch in pbar:\n",
    "            student_model.train()\n",
    "            pixel_values = batch['pixel_values'].to(train_params.device)\n",
    "            labels = batch['labels'].to(train_params.device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            student_outputs = student_model(pixel_values=pixel_values, labels=labels, output_attentions=True)\n",
    "            loss, student_logits = student_outputs.loss, student_outputs.logits\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_output = teacher_model(pixel_values=pixel_values, labels=labels, output_attentions=True)\n",
    "\n",
    "\n",
    "            last_layer_loss = calc_last_layer_loss(\n",
    "                student_logits,\n",
    "                teacher_output.logits,\n",
    "                train_params.temperature,\n",
    "                train_params.last_layer_loss_weight,\n",
    "            )\n",
    "\n",
    "            student_attentions, teacher_attentions = student_outputs.attentions, teacher_output.attentions\n",
    "\n",
    "            intermediate_layer_loss = calc_intermediate_layers_loss(\n",
    "                student_attentions,\n",
    "                teacher_attentions,\n",
    "                train_params.intermediate_layers_weights,\n",
    "                student_teacher_attention_mapping,\n",
    "            )\n",
    "\n",
    "            total_loss = loss * train_params.loss_weight + last_layer_loss\n",
    "            if intermediate_layer_loss is not None:\n",
    "                total_loss += intermediate_layer_loss\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_description(f'total loss: {total_loss.item():.3f}')\n",
    "\n",
    "            for loss_value, loss_name in (\n",
    "                (loss, 'loss'),\n",
    "                (total_loss, 'total_loss'),\n",
    "                (last_layer_loss, 'last_layer_loss'),\n",
    "                (intermediate_layer_loss, 'intermediate_loss'),\n",
    "\n",
    "            ):\n",
    "                if loss_value is None: \n",
    "                    continue\n",
    "                tb_writer.add_scalar(\n",
    "                    tag='loss_name',\n",
    "                    scalar_value=loss_value.item(),\n",
    "                    global_step=step,\n",
    "                )\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'model': student_model,\n",
    "                'state_dict': student_model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "            },\n",
    "            f'{save_dir}/ckpt_{epoch}.pth',\n",
    "        )\n",
    "\n",
    "        eval_metrics = evaluate_model(student_model, valid_dataloader, student_model.config.id2label)\n",
    "\n",
    "        for metric_key, metric_value in eval_metrics.items():\n",
    "            if not isinstance(metric_value, float):\n",
    "                continue\n",
    "            tb_writer.add_scalar(\n",
    "                tag=f'eval_{metric_key}',\n",
    "                scalar_value=metric_value,\n",
    "                global_step=epoch,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 1.158: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [08:40<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.203162984490462\n",
      "Mean accuracy: 0.27617739104473876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 0.905: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [08:41<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.2359690789724595\n",
      "Mean accuracy: 0.30320209761347188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 0.951: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [08:41<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.254198045234024574\n",
      "Mean accuracy: 0.32577089057276448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 1.120: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [08:40<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.27636647347537965\n",
      "Mean accuracy: 0.357638286365548505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 1.054: 100%|█████████████████████████████████████████████████████████████████████████████████| 2526/2526 [08:40<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.29115568926948165\n",
      "Mean accuracy: 0.3725840250266807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "otal loss: 0.841:   0%|▏                                                                                   | 4/2526 [00:01<15:26,  2.72it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistilled_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudent_teacher_attention_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_teacher_attention_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtb_writer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(teacher_model, student_model, train_params, student_teacher_attention_mapping, tb_writer, save_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mstudent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# get the inputs;\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(train_params\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/test/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2827\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2822\u001b[0m             submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[1;32m   2823\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2824\u001b[0m                 memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2825\u001b[0m             )\n\u001b[0;32m-> 2827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, mode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Set the module in training mode.\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \n\u001b[1;32m   2830\u001b[0m \u001b[38;5;124;03m    This has any effect only on certain modules. See documentations of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=deepcopy(distilled_model),\n",
    "    train_params=train_params,\n",
    "    student_teacher_attention_mapping=student_teacher_attention_mapping,\n",
    "    tb_writer=tb_writer,\n",
    "    save_dir=save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_0.pth  ckpt_4.pth\n",
      "ckpt_1.pth  events.out.tfevents.1734581428.archlinux.14706.1\n",
      "ckpt_2.pth  events.out.tfevents.1734583012.archlinux.14706.2\n",
      "ckpt_3.pth\n"
     ]
    }
   ],
   "source": [
    "!ls prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14706/3290740123.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  prune_distilled_model = torch.load('prune/ckpt_4.pth')[\"model\"]\n"
     ]
    }
   ],
   "source": [
    "prune_distilled_model = torch.load('prune/ckpt_4.pth')[\"model\"]\n",
    "teacher_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "teacher_model.to(device)\n",
    "model = None\n",
    "distilled_model =None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.29115568926948165\n",
      "Mean accuracy: 0.3725840250266807\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(prune_distilled_model, valid_dataloader, prune_distilled_model.config.id2label)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model = None\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import islice\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.ao.quantization import get_default_qconfig_mapping\n",
    "from torch.quantization.quantize_fx import convert_fx\n",
    "from torch.quantization.quantize_fx import prepare_fx\n",
    "from torch.utils.data import DataLoader\n",
    "QCONFIG_MAPPING = get_default_qconfig_mapping(\"x86\")\n",
    "\n",
    "def quantize_static(\n",
    "        model: nn.Module,\n",
    "        data_loader: DataLoader,\n",
    "        num_batches: int = 8,\n",
    "        device: str = 'cuda'\n",
    ") -> nn.Module:\n",
    "  \n",
    "    prepared_model = deepcopy(model)\n",
    "    prepared_model.eval()\n",
    "    example_input = next(iter(data_loader))\n",
    "    prepared_model = prepare_fx(\n",
    "        model=prepared_model,\n",
    "        qconfig_mapping=QCONFIG_MAPPING,\n",
    "        example_inputs=(example_input, ),\n",
    "    )\n",
    "   \n",
    "    device = torch.device(device)\n",
    "\n",
    "    prepared_model.eval()\n",
    "    prepared_model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, _ in islice(data_loader, num_batches):\n",
    "            prepared_model(image.to(device))\n",
    "\n",
    " \n",
    "    prepared_model.cpu()\n",
    "    quantized_model = convert_fx(prepared_model)\n",
    "    return quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADEChallengeData2016/images/validation\n"
     ]
    }
   ],
   "source": [
    "calibrate_ds = SemanticSegmentationDataset(root_dir=root_dir, image_processor=image_processor, train=False)\n",
    "calibrate_dataloader = DataLoader(calibrate_ds, batch_size=batch_size,num_workers=14,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qaunt_prune_distilled_model =quantize_static(deepcopy(prune_distilled_model), calibrate_dataloader, num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qaunt_prune_distilled_model = torch.quantization.quantize_dynamic(\n",
    "#     deepcopy(prune_distilled_model), dtype=torch.qint8\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(qaunt_prune_distilled_model, valid_dataloader, qaunt_prune_distilled_model.config.id2label)\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np  \n",
    "\n",
    "def test_pt(model_test ,batch=1,it=30):\n",
    "    with torch.inference_mode():\n",
    "        torch.cuda.synchronize()\n",
    "        #warm up \n",
    "        input_example = torch.rand(batch,3,512,512, device=\"cuda\")\n",
    "    \n",
    "        for _ in range(10):\n",
    "            model_test(input_example)\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "            \n",
    "        starttime = time.perf_counter()\n",
    "        for _ in range(it):\n",
    "            model_test(input_example)\n",
    "            torch.cuda.synchronize()\n",
    "    \n",
    "        return timedelta(seconds=time.perf_counter()-starttime)/it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_1 = test_pt(prune_distilled_model).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.29115568926948165\n",
      "Mean accuracy: 0.3725840250266807\n"
     ]
    }
   ],
   "source": [
    "m_o = evaluate_model(prune_distilled_model, valid_dataloader, prune_distilled_model.config.id2label)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t_1 = test_pt(teacher_model).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.36103305469415725\n",
      "Mean accuracy: 0.4731817117838845\n"
     ]
    }
   ],
   "source": [
    "m_t = evaluate_model(teacher_model, valid_dataloader, prune_distilled_model.config.id2label)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_10 = test_pt(prune_distilled_model,10).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t_10=test_pt(teacher_model,10).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_o_20 = test_pt(prune_distilled_model,20).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t_20 = test_pt(teacher_model,20).microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6833816244508832"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t_20/b_o_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5491360212671688"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t_10/b_o_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1645207439198857"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t_1/b_o_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_opt =[]\n",
    "test_base = []\n",
    "for i in range(1,20,3):\n",
    "    test_opt.append(test_pt(prune_distilled_model,i).microseconds)\n",
    "    test_base.append(test_pt(teacher_model,i).microseconds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(1,20,3)),test_opt , list(range(1,20,3)),test_base ,marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.682554532473288"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_base[-1]/test_opt[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.29115568926948165),\n",
       " np.float64(0.36103305469415725),\n",
       " np.float64(0.3725840250266807),\n",
       " np.float64(0.4731817117838845))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_o['mean_iou'],m_t['mean_iou'],m_o['mean_accuracy'],m_t['mean_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8064516129032258, 0.7874015748031495)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(m_o['mean_iou']/m_t['mean_iou']),float(m_o['mean_accuracy']/m_t['mean_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(\n",
    "    ['mean_iou_base','mean_iou_opt','mean_accuracy_base','mean_accuracy_opt'],\n",
    "    [m_t['mean_iou'],m_o['mean_iou'],m_t['mean_accuracy'],m_o['mean_accuracy']]  ,align='edge'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2339351,
     "sourceId": 3970685,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
